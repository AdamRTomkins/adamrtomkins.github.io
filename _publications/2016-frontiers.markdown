---
layout: publication
title: From GUI to GPU, A toolchain for GPU code generation for large scale Drosophila simulations using SpineML
authors: Adam Tomkins, Carlos Luna Ortiz, Daniel Coca and Paul Richmond
journal: Frontiers in Neuroinformatics
doi: 10.3389/conf.fninf.2016.20.00049
year: 2016
link: http://www.frontiersin.org/10.3389/conf.fninf.2016.20.00049/event_abstract
---

The importance of simulator-independent high-level model-description languages for model building, sharing, and integration in computational neuroscience has been well established. Simulator independence is essential to ensure that complex models are both testable and reproducible. However the adoption of standardisation has been hampered by the current difficulty of developing and visualising Layered XML models, due to a lack of intuitive model creation tools.

Concurrently, the development of increasingly complex and comprehensive simulations, such as whole-brain emulation, require a shift to massively parallel programming paradigms.  GPU utilization has proven to be a powerful tool for reducing execution times of  the large-scale models required for rapid hypothesis generation and testing. Problematically, while parallel programming is a powerful tool, it is notoriously difficult and time consuming for non-experts to develop efficient, portable and testable code. 

This requirement for efficient GPU-level programming presents a further barrier to entry for open-science, due to both the increased financial burden of GPU infrastructure, and the specialized knowledge needed for proficiency specific GPU programming paradigms. This in turn negatively impacts the progress model sharing and integration.

Here we describe a complete GUI to GPU tool chain based on SpineML (Richmond et al, 2014) , a LEMS derived layered neural modeling language (Cannon et al. 2014), and the associated graphical user interface, SpineCreator. We demonstrate easy development of large scale neural networks, with support for both CPU and GPU code generation. We prototype both local and remote code execution, encouraging large-scale, parallel-execution of standardised model specifications, with seamless model sharing. We demonstrate the capability of running these models both on local hardware, and with easily set up cloud computing services, enabling GPU utilization, without requiring the considerable time and financial investments associated with GPU development and maintenance... 

For the full text visit [Frontiers in Neuroinformatics](http://www.frontiersin.org/10.3389/conf.fninf.2016.20.00049/event_abstract)
